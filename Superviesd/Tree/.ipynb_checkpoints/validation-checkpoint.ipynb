{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5609b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Validation set\n",
    "\n",
    "#Until now, we use test_set for evaluate model. \n",
    "#However, if you repeatedly use test_set and find the optimal model, there is a disadvantage that a model that fits test_set is created.\n",
    "#So from now, we use validation set. We can separate train set fot make this like test_set.\n",
    "#Example\n",
    "    #Separate 20% from train_set for test_set and again 20% for validation set. \n",
    "    #Find optimal hyperparameter use train_set(60%), validation set(20%)\n",
    "    #After find, give the final score as train_set + validation set(80%)  and test_set(20%)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "\n",
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()  #2-dimension array\n",
    "target = wine['class'].to_numpy()                  #linear array.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#separate test_data from whole (20% for test, 80% for train data)\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size = 0.2\n",
    "                                                                      , random_state = 42)\n",
    "\n",
    "#separate validation_data from remain train_data (20% of train data(it is 16% of all data))\n",
    "sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size = 0.2\n",
    "                                                                , random_state = 42)\n",
    "\n",
    "print(sub_input.shape, val_input.shape)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt.fit(sub_input, sub_target)\n",
    "print(dt.score(sub_input, sub_target))\n",
    "print(dt.score(val_input, val_target))\n",
    "#As we can see, It is overfitting to train_set. We have to change parameter for find better model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n---------- from now, outputs are for Cross validation -------------')\n",
    "##Cross validation\n",
    "#devide train set into k folds\n",
    "#Each fold is used validation data in turn. Remain k-1 folds are used train_set.\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(dt, train_input, train_target)\n",
    "print('fit_time : ', scores['fit_time'])\n",
    "print('score_time : ', scores['score_time'])\n",
    "print('test_score : ', scores['test_score'])\n",
    "#cross_validate() method return dictionary form(key-value form), this method default do 5-cross validation, we can change k value using cv parameter\n",
    "    #fit_time : time taken to train model\n",
    "    #score_time : time taken to scoring\n",
    "    #test_score : validation_score for each fold  (scored by validation data)\n",
    "    #train_score : train score for each fold      (scored by train data) (it is printed when return_train_score=True)\n",
    "#Final score is average of test_score (It's name is test_score but don't forget, it is score of validation fold)\n",
    "import numpy as np\n",
    "print('final score of model : ', np.mean(scores['test_score']))\n",
    "\n",
    "#this block is same with upper block --> 5-cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold())\n",
    "print(np.mean(scores['test_score']))\n",
    "\n",
    "#10-cross validation\n",
    "splitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "scores = cross_validate(dt, train_input, train_target, cv = splitter)\n",
    "print('final score of model : ', np.mean(scores['test_score']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n---------- from now, outputs are for Grid Search -------------')\n",
    "##Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'min_impurity_decrease' : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}\n",
    "print('params : ', params['min_impurity_decrease'])\n",
    "#make dictionary. Key value is name of be serched parameter, value is range of parameter can get\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, n_jobs=-1)\n",
    "gs.fit(train_input, train_target)\n",
    "#사이킷런의 그리드서치는 찾아낸 최적의 파라미터 조합으로 전체 훈련 세트에서 자동으로 다시 훈련을 진행한다. 그리고 그 모델을 best_estimator_에 저장한다.\n",
    "#dt is best decision tree model that founded by GreedSearch\n",
    "dt = gs.best_estimator_\n",
    "print('score : ', dt.score(train_input, train_target))\n",
    "#Best hyper parameters that grid search class found is contatined in best_params_\n",
    "print('best parameters that GSmodel found : ', gs.best_params_)\n",
    "#average score of cross_validation for each hyperparameter candidates is contained in 'mean_test_score' key value of gs.cv_results_ dictionary\n",
    "print('average score for each hyperparameter candidate : ', gs.cv_results_['mean_test_score'])\n",
    "\n",
    "\n",
    "\n",
    "######### Visualizing Result #########\n",
    "import matplotlib.pyplot as plt\n",
    "#x-label : value of dictionary 'min_impurity_decrease'\n",
    "#y-label : value of cv_results_['mean_test_score']\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Hyper Parmeter Tuing')\n",
    "plt.xticks([0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006])\n",
    "plt.xlabel('Candidate Of Hyper Parameter')\n",
    "plt.ylabel('Average Score of Cross Validation')\n",
    "plt.scatter(params['min_impurity_decrease'], gs.cv_results_['mean_test_score'])\n",
    "plt.show()\n",
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "best_index = np.argmax(gs.cv_results_['mean_test_score'])\n",
    "print('best value of hyper parameter among candidates : ', gs.cv_results_['params'][best_index])\n",
    "\n",
    "#######\n",
    "#use grid search on more complex parameters - find best combination of three hyperparameters\n",
    "params = {\n",
    "    'min_impurity_decrease' : np.arange(0.0001, 0.001, 0.0001),\n",
    "    'max_depth' : range(5, 20, 1),\n",
    "    'min_samples_split' : range(2, 200, 10)\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, n_jobs=-1)\n",
    "gs.fit(train_input, train_target)\n",
    "print(gs.best_params_)\n",
    "print(np.max(gs.cv_results_['mean_test_score']))\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n---------- from now, outputs are for Random Search -------------')\n",
    "##Random Search\n",
    "from scipy.stats import uniform, randint\n",
    "#uniform - 실수값  랜덤하게 뽑음\n",
    "#randint - 정수값  랜덤하게 뽑음. --> C/C++의 rand()랑 동일하게 작동 하는듯?\n",
    "\n",
    "rgen = randint(0,10)\n",
    "rgen.rvs(10)\n",
    "\n",
    "np.unique(rgen.rvs(1000), return_counts=True)\n",
    "\n",
    "ugen = uniform(0,1)\n",
    "ugen.rvs(10)\n",
    "\n",
    "\n",
    "#select kind of parameters that model will find\n",
    "params = {\n",
    "    'min_impurity_decrease' : uniform(0.0001, 0.001),\n",
    "    'max_depth' : randint(20, 50),\n",
    "    'min_samples_split' : randint(2, 25),\n",
    "    'min_samples_leaf' : randint(1, 25),\n",
    "    }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42)\n",
    "gs.fit(train_input, train_target)\n",
    "print(gs.best_params_)\n",
    "print(np.max(gs.cv_results_['mean_test_score']))\n",
    "dt = gs.best_estimator_\n",
    "print(dt.score(test_input, test_target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
